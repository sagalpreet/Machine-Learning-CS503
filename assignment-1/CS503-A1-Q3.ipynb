{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71b1d27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import csv\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b13c92",
   "metadata": {},
   "source": [
    "## Linear Ridge Regression in Multiple Dimension [Medium]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "883981bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilities for creating a dataset\n",
    "\n",
    "### data structure to represent dataset\n",
    "class Dataset:\n",
    "    def __init__(self, x: np.ndarray, y: np.ndarray, n = None):\n",
    "        # todo: assertion to verify the dimension of x and y\n",
    "        self.__x = x\n",
    "        self.__y = y\n",
    "        self.__n = n if n else len(x)\n",
    "    \n",
    "    @property\n",
    "    def x(self):\n",
    "        return self.__x\n",
    "\n",
    "    @property\n",
    "    def y(self):\n",
    "        return self.__y\n",
    "    \n",
    "    @x.setter\n",
    "    def x(self, value):\n",
    "        self.__x = value\n",
    "        \n",
    "    @y.setter\n",
    "    def y(self, value):\n",
    "        self.__y = value\n",
    "        \n",
    "    def __getitem__(self, index: int):\n",
    "        #todo: assertion to verify out of bounds\n",
    "        return self.__x[index], self.__y[index]\n",
    "    \n",
    "    def __setitem__(self, index: int, x_: np.ndarray, y_: np.ndarray):\n",
    "        # todo: assertion to verify out of bounds\n",
    "        self.__x[index] = x_\n",
    "        self.__y[index] = y_\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.__n\n",
    "    \n",
    "    def __del__(self):\n",
    "        del(self.__x)\n",
    "        del(self.__y)\n",
    "        del(self.__n)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        self.__index = 0\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if (self.__index < self.__n):\n",
    "            self.__index += 1\n",
    "            return self[self.__index - 1]\n",
    "        raise StopIteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0aa5720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data and create a dataset out of it\n",
    "# NOTE: The only label field must be the last column\n",
    "\n",
    "def read_raw(path: str):\n",
    "    # read raw data from csv\n",
    "    # convert str to float\n",
    "    # for every field possible\n",
    "    file = open(path, \"r\")\n",
    "    raw_data = csv.reader(file, delimiter = ',')\n",
    "    \n",
    "    data = []\n",
    "    for row in raw_data:\n",
    "        for (i, value) in enumerate(row):\n",
    "            try:\n",
    "                row[i] = float(value)\n",
    "            except:\n",
    "                pass\n",
    "        data.append(row)\n",
    "    file.close()\n",
    "    \n",
    "    return data\n",
    "\n",
    "def get_field_info(data):\n",
    "    num_rows, num_cols = len(data), len(data[0])\n",
    "    \n",
    "    # extract information about numeric and non-numeric fields\n",
    "    non_numeric_fields = {}\n",
    "    numeric_fields = set([])\n",
    "    \n",
    "    for index in range(num_cols-1):\n",
    "        if type(data[0][index]) == float:\n",
    "            numeric_fields.add(index)\n",
    "            continue\n",
    "        # for each non-numeric field, we maintain information about number\n",
    "        # and types of different values possible for that field\n",
    "        non_numeric_fields[index] = {'count': -1, 'values': {}}\n",
    "    \n",
    "    for row in data:\n",
    "        for index, field in non_numeric_fields.items():\n",
    "            value = row[index]\n",
    "            if (value not in field['values']):\n",
    "                field['count'] += 1\n",
    "                field['values'][value] = field['count']\n",
    "    \n",
    "    return non_numeric_fields, numeric_fields\n",
    "\n",
    "def construct_design_matrix(data, non_numeric_fields, numeric_fields):\n",
    "    num_rows, num_cols = len(data), len(data[0])\n",
    "    \n",
    "    # constructing desired design matrix and label vector.\n",
    "    # we encode non-numeric values using one-hot encoding.\n",
    "    \n",
    "    # however, after one hot encoding, we eliminate a column\n",
    "    # for each original non-numeric field to reduce correlation\n",
    "    # between newly formed fields\n",
    "    \n",
    "    X, Y = [], []\n",
    "    \n",
    "    for i, row in enumerate(data):\n",
    "        x = []\n",
    "        Y.append(row[num_cols-1])\n",
    "        for index in range(num_cols - 1):\n",
    "            \n",
    "            value = row[index]\n",
    "            \n",
    "            # append numeric feature as it is\n",
    "            if (index in numeric_fields):\n",
    "                x.append(row[index])\n",
    "                continue\n",
    "                \n",
    "            # encode non-numeric feature and append\n",
    "            field = non_numeric_fields[index]\n",
    "            one_hot_encoded = [0]*field['count']\n",
    "            pos = field['values'][value]\n",
    "            if (pos): one_hot_encoded[pos-1] = 1\n",
    "            x.extend(one_hot_encoded)\n",
    "        \n",
    "        X.append(x)\n",
    "    \n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "def get_dataset(path: str, hasHeader = True):\n",
    "    \n",
    "    data = read_raw(path)\n",
    "    \n",
    "    # remove first row if it is a header\n",
    "    if (hasHeader):\n",
    "        data = data[1:]\n",
    "    \n",
    "    # check if there is data\n",
    "    if (not data):\n",
    "        raise IndexError('No data in the given file')\n",
    "    \n",
    "    # extract information about numeric and non-numeric fields\n",
    "    non_numeric_fields, numeric_fields = get_field_info(data)\n",
    "    \n",
    "    X, Y = construct_design_matrix(data, non_numeric_fields, numeric_fields)\n",
    "    \n",
    "    return Dataset(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fea871a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up path of .csv file\n",
    "path = 'dataset/insurance.csv'\n",
    "\n",
    "dataset = get_dataset(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfadd23",
   "metadata": {},
   "source": [
    "#### Feature Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fd5cfab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying Mean and Variance for Normalized Data (for each feature):\n",
      "Mean\t\t[[-0. -0.  0.  0.  0.  0.  0. -0.]]\n",
      "Variance\t[[1. 1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# normalize a 2-d matrix\n",
    "\n",
    "def get_mean_variance(matrix):\n",
    "    num_rows, num_cols = matrix.shape\n",
    "    mean = np.sum(matrix, axis=0, keepdims=True) / num_rows\n",
    "    variance = (np.sum((matrix - mean) ** 2, axis=0, keepdims=True) / (num_rows))\n",
    "    return mean, variance\n",
    "\n",
    "def normalize(matrix, mean, variance):\n",
    "    std = variance ** 0.5\n",
    "    return (matrix - mean) / std\n",
    "\n",
    "dataset.x = normalize(dataset.x, *get_mean_variance(dataset.x))\n",
    "mean, variance = get_mean_variance(dataset.x)\n",
    "print(f'Verifying Mean and Variance for Normalized Data (for each feature):\\nMean\\t\\t{np.around(mean, 4)}\\nVariance\\t{np.around(variance, 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46917a40",
   "metadata": {},
   "source": [
    "#### Partition dataset into training, validation and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac74c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937e2e43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4370129f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff28e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
